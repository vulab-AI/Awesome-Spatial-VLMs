{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140768b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuo/anaconda3/envs/vpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer\n",
    "from modeling_qwen2_vl_vpt import VPT_Qwen2VLForConditionalGeneration, VPT_Qwen2VLProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eca728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 14.39it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"rp-yu/Qwen2-VL-7b-VPT-CLIP\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 加载模型\n",
    "processor = VPT_Qwen2VLProcessor.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "model = VPT_Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_path, torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a922f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 测试样例\n",
    "image = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "question = \"Identify the region that can help you answer the question, and then answer the question: What is the left side of the green cup? <image>\"\n",
    "\n",
    "model_inputs = processor(images=image, text=question, return_tensors=\"pt\").to(device)\n",
    "output_ids = model.generate(**model_inputs, max_new_tokens=256)\n",
    "answer = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77109262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: Identify the region that can help you answer the question, and then answer the question: What is the left side of the green cup? <image><|region_token_start|><|x_0|><|y_0|><|x_7|><|y_7|><|y_7|><|region_token_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Answer:\", answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa8f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(['<|x_0|>', '<|x_7|>'], ['<|y_0|>', '<|y_7|>'])], True)\n"
     ]
    }
   ],
   "source": [
    "Action_tokens = {\n",
    "    \"region_x\": \"<|x_0|>,<|x_1|>,<|x_2|>,<|x_3|>,<|x_4|>,<|x_5|>,<|x_6|>,<|x_7|>\".split(\",\"),\n",
    "    \"region_y\": \"<|y_0|>,<|y_1|>,<|y_2|>,<|y_3|>,<|y_4|>,<|y_5|>,<|y_6|>,<|y_7|>\".split(\",\"),\n",
    "    \"dino\": \"<|detection_action_start|>\",\n",
    "    \"clip\": \"<|clip_action_start|>\",\n",
    "    \"sam\": \"<|seg_action_start|>\",\n",
    "}\n",
    "\n",
    "def check_region_tokens(text):\n",
    "\n",
    "    pattern = re.compile(r'<\\|region_token_start\\|>(<\\|[xy]_[01234567]\\|>)+<\\|region_token_end\\|>')\n",
    "    matches = pattern.finditer(text)\n",
    "\n",
    "    found_tokens = []\n",
    "    for match in matches:\n",
    "        match_str = match.group()\n",
    "        # match_str = match_str.replace(\"<|region_token_start|>\",\"\").replace(\"<|region_token_end|>\",\"\")\n",
    "        match_tokens_x = [token for token in Action_tokens[\"region_x\"] if token in match_str]\n",
    "        match_tokens_y = [token for token in Action_tokens[\"region_y\"] if token in match_str]\n",
    "        found_tokens.append((match_tokens_x, match_tokens_y))\n",
    "\n",
    "    if found_tokens:\n",
    "        return found_tokens, True\n",
    "    else:\n",
    "        return None, False\n",
    "\n",
    "text= check_region_tokens(answer[0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ef32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66549279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
