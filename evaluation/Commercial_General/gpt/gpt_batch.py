from openai import OpenAI
import os
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

api_key ="your-openai-api-key"

client = OpenAI(api_key=api_key)

# é…ç½®æ–‡ä»¶å¤¹ !!!!
json_folders = "gpt5_jsonls"
output_folders = "gpt5_results"

## åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
os.makedirs(output_folders, exist_ok=True)

def process_jsonl(jsonlfile):
    """å¤„ç†å•ä¸ª JSONL æ–‡ä»¶ï¼šä¸Šä¼  -> æäº¤ -> è½®è¯¢ -> ä¿å­˜ç»“æœ"""
    try:
        print(f"ğŸš€ Processing file: {jsonlfile}", flush=True)

        # Step 1. ä¸Šä¼ 
        batch_input_file = client.files.create(
            file=open(os.path.join(json_folders, jsonlfile), "rb"),
            purpose="batch"
        )
        print(f"âœ… Uploaded {jsonlfile}: {batch_input_file.id}", flush=True)

        # Step 2. åˆ›å»º batch
        job = client.batches.create(
            input_file_id=batch_input_file.id,
            endpoint="/v1/chat/completions",
            completion_window="24h",
            metadata={
                "description": "spatial eval",
                "version": "1.0.0",
                "source_file": jsonlfile
            }
        )
        print(f"ğŸ“Œ Job created for {jsonlfile}: {job.id}", flush=True)

        # Step 3. è½®è¯¢
        while True:
            batch = client.batches.retrieve(job.id)
            print(f"â³ {jsonlfile} status: {batch.status}", flush=True)

            if batch.status in ["completed", "failed", "expired", "cancelled"]:
                break
            time.sleep(60)

        # Step 4. ä¿å­˜ç»“æœ
        if batch.status == "completed" and batch.output_file_id:
            result_content = client.files.content(batch.output_file_id).text
            output_path = os.path.join(
                output_folders, jsonlfile.replace(".jsonl", "_result.jsonl")
            )
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(result_content)
            print(f"âœ… Results saved: {output_path}", flush=True)
        else:
            print(f"âŒ {jsonlfile} failed with status={batch.status}", flush=True)

    except Exception as e:
        print(f"ğŸ”¥ Error processing {jsonlfile}: {e}", flush=True)


if __name__ == "__main__":
    files = [f for f in os.listdir(json_folders) if f.endswith(".jsonl")]

    # é™åˆ¶çº¿ç¨‹æ•°ï¼Œé¿å…è¿‡å¤šå¹¶å‘è¯·æ±‚
    max_workers = min(6, len(files))  # å¯ä»¥æ”¹å¤§æˆ–æ”¹å°
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_jsonl, f) for f in files]
        for future in as_completed(futures):
            future.result()  # æŠ›å‡ºå¼‚å¸¸æ—¶ç«‹åˆ»æ˜¾ç¤º
1