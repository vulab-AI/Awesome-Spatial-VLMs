## ðŸ“Š Spatial Benchmark Collection

<div style="overflow-x:auto;">
<table style="border-collapse:collapse;font-size:13px;width:100%;">
<thead><tr style="background-color:#f5f5f5;"><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Dataset</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Venue</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">P.</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">U.</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">E.</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Fundamental Task</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Size</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Image Source</th><th style="border:1px solid #ccc;padding:4px 6px;text-align:center;">Modality</th></tr></thead><tbody>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="">Ori-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">orientation estimation</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">400</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO, Generated from DALL-E</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/jhCOR/EgoOrientBench">EgoOrientBench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">orientation estimation</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">33,460</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ImageNet, D3, DomainNet, PACS, OmniObject3D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://drive.google.com/drive/folders/13WqSuUNV007oQp-u4t0FA51ZOI7BqAaG">GeoMeter</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPRW2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">11,200</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">synthetic data</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/OpenGVLab/CRPE">CRPE-relation</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ECCV2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">7,576</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/open-compass/VLMEvalKit">MMBench(physical, spatial relation)</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">251</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Online</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/AILab-CVC/SEED-Bench">SEED-Bench (Spatial Rel., Instance Loc.)</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,634</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CC3M</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/yuweihao/MM-Vet">MM-Vet(Spatial awareness (Spat))</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICML2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">75</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Online</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/cambridgeltl/topviewrs">TopViewRS</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">EMNLP2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">11,384</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Matterport3D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB, 3D Mesh</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/darkyarding/MME">MME(position split)</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">60</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/Phineas476/EmbSpatial-Bench">EmbSpatial-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ACL2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3,640</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MP3D, AI2-THOR, ScanNet</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/amitakamath/whatsup_vlms">What's Up</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">EMNLP2023</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">4,138</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO,GQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/UCSB-NLP-Chang/Visual-Spatial-Planning">VSP</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">4,600</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">OpenAI Gym, BIRD</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MapBench</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,649</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">online</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/MLL-Lab/MindCube">MINDCUBE</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">21,154</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArkitScenes,DL3DV-10K,WildRGB-D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/RunsenXu/MMSI-Bench">MMSI-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,000</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Matterport3D, ScanNet, ...</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/StephenZhu/CoSpace">CoSpace</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,626</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Baidu Map Panorama API, HM3D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/apple/ml-space-benchmark">SPACE-Visual</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICLR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Situated Reasoning, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">5,008</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Synthetic Data, Oline</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/nyu-visionx/CV-Bench">CV-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">NeurIPS2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Depth Estimation, Spatial Relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,638</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO,ADE20K, Omini3D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/a8cheng/SpatialRGPT-Bench">SpatialRGPT-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Neurips2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Depth Estimation, Spatial Relations VQA,</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,410</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">nuScenes,Hypersim, SUNRGBD, KITTI, ARKitScenes ...</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/andrewliao11/Q-Spatial-Bench">Q-Spatial</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">EMNLP2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">271</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ScanNet, images captured by iPhone</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/BAAI-DCAI/SpatialBot">SpatialBench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICRA2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation, Spatial relations VQA, 3D object detection,</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">182</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MME and manually annotated images</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB-D</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/dmarsili/Omni3D-Bench">Omni3D-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">500</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Omni3D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/MINT-SJTU/STI-Bench">STI-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICCV2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations, orientation estimation</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,060</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Waymo, ScanNet, Omni6DPose</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/BAAI/RefSpatial-Bench">RefSpatial-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">NeurIPS2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection,Depth estimation,Spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">200</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">manually collect</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/yliu-cs/SSRBench">SSRBENCH-Spatial</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">NeurIPS2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection,Spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">357</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">SSR-CoT</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB-D</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/BLINK-Benchmark/BLINK">BLINK</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ECCV2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation, Spatial simulation in inferring, Spatial situated reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3,807</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">HPatches</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/ch-chenyu/All-Angles-Bench">All-Angles-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation, Spatial simulation in inferring, Spatial situated reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,132</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Exo4D, EgoHumans</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/Endlinc/SpaceSGG-Val/viewer/default/train?p=1">SpaceSGG-Val</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">WACV2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Simulation and Inferring, Spatial Situated Reasoning, Spatial relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">271</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">COCO</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/Space3D-Bench/Space3D-Bench">Space3D-Bench(Relation, Navigation, Prediction)</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ECCV2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial Simulation and Inferring, Spatial Situated Reasoning, Spatial relations VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,000</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Replica</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB, 3D Mesh</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/MilaWang/SpatialEval">SpatialEval(VQA, VTQA)</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Neurips2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial situated reasoning, spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">9,270</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">synthetic, Densely Captioned Images (DCI)</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/MilaWang/SpatialEval">3DSRBench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICCV2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial situated reasoning, spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,170</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MS-COCO, HSSD</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/cambridgeltl/visual-spatial-reasoning/tree/master/data">VSR</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ACL2023</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial situated reasoning, spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">10,972</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MS-COCO</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/RyanWW/Spatial457">Spatial457</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial simulation in inferring, spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">23,752</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">synthetic data</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/sled-umich/COMFORT">COMFORT</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ICLR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Spatial situated reasoning, spatial relation VQA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">58,320</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">synthetic data</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/stogian/srbench">SRBench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Orientation Estimation, Spatial Relations VQA, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,800</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">classic Mental Rotation Test, EgoOrientBench, Spatial-MM</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/nyu-visionx/VSI-Bench">VSI-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D object detection, Spatial relations VQA, Spatial situated reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">5,130</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ScanNet, ScanNet++, and ARKitScenes</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/visheratin/realworldqa">RealWorldQA</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">-</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation, Spatial relations VQA, Spatial simulation in inferring, Spatial situated reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">765</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">NA</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/jasonzhango/SPAR-Bench">SPAR-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">depth estimation, Spatial relations VQA, Spatial simulation in inferring, Spatial situated reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">7,207</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">SPAR-7M</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/wei2912/SPHERE-VLM">SPHERE</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA, Spatial Simulation and Inferring, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,285</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MS COCO-2017</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/lidingm/ViewSpatial-Bench">ViewSpatial-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">orientation estimation, Spatial relations VQA, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">5,700</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MS-CoCo, ScanNet</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://github.com/FatemehShiri/Spatial-MM">Spatial-MM</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">EMNLP2024</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Orientation Estimation, Spatial Relations VQA, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,310</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Onlin</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/haoningwu/SpatialScore">SpatialScore</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA, Spatial Situated Reasoning, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">28,000</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">MMVP, MMIU, RealWorldQA , SpatialSense, SpatialBench, ...</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/qizekun/OmniSpatial">OmniSpatial</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Depth Estimation, orientation estimation, Spatial Relations VQA, Spatial Situated Reasoning, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,500</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Web Images, Exam-Based Test Questions, Driving Test Questions, MME, HOI4D</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/franky-veteran/SITE-Bench">SITE-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection Spatial Relations VQA Spatial Situated Reasoning Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">8,068</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">VSI-Bench, Blink, VSR, MMBench, ...</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/chanhee-luke/RoboSpatial-Home">RoboSpatial-Home</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">CVPR2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection Spatial Relations VQA Spatial Situated Reasoning Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">350</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">manually collect</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB-D</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/vbdai/Ego3D-Bench">Ego3D-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection,Spatial Relations,Spatial Simulation and Inferring, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">8,600</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">manually collect</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/cpystan/MSMU/viewer/default/test">MSMU-Bench</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">NeurIPS2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA, Spatial Simulation and Inferring</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">1,000</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ScanNet, ScanNet++</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB-D</td></tr>
<tr style="background-color:#fafafa;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/YuyouZhang/SpinBench">SPINBENCH</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Depth Estimation, Spatial Relations VQA, Spatial Simulation and Inferring, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">2,599</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">Synthetic data, Multi-View Car Dataset, Stereo Face Database</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB</td></tr>
<tr style="background-color:#ffffff;"><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;"><a href="https://huggingface.co/datasets/Cusyoung/SpaCE-10">SPACE-10</a></td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">ArXiv2025</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">âœ“</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">3D Object Detection, Spatial Relations VQA, Spatial Simulation and Inferring, Spatial Situated Reasoning</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">5,000</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">SCN, 3RS, ARK, SCN++</td><td style="border:1px solid #ddd;padding:3px 5px;text-align:center;">RGB, Point Cloud</td></tr>
</tbody></table></div>

> Total: **40 datasets Ã— 9 columns**
